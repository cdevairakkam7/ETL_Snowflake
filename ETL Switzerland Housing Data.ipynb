{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1e6f308-df41-432a-a3d4-e468c9a89352",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading all Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19facedf-b1ed-418f-b3fe-f7c0d0caa96f",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\n",
      "Collecting snowflake-connector-python\n",
      "  Downloading snowflake_connector_python-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (3.4.8)\n",
      "Collecting pyjwt<3.0.0\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (1.26.9)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.9/dist-packages (from snowflake-connector-python) (3.9.0)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from snowflake-connector-python) (2.6.2)\n",
      "Collecting tomlkit\n",
      "  Downloading tomlkit-0.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2021.10.8)\n",
      "Requirement already satisfied: pytz in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2021.3)\n",
      "Collecting pyOpenSSL<24.0.0,>=16.2.0\n",
      "  Downloading pyOpenSSL-23.3.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (3.3)\n",
      "Requirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (21.3)\n",
      "Collecting typing-extensions<5,>=4.3\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (1.15.0)\n",
      "Collecting sortedcontainers>=2.4.0\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests<3.0.0 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2.27.1)\n",
      "Requirement already satisfied: pycparser in /databricks/python3/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Collecting cryptography<42.0.0,>=3.1.0\n",
      "  Downloading cryptography-41.0.5-cp37-abi3-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->snowflake-connector-python) (3.0.4)\n",
      "Installing collected packages: cryptography, typing-extensions, tomlkit, sortedcontainers, pyOpenSSL, pyjwt, asn1crypto, snowflake-connector-python\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 3.4.8\n",
      "    Not uninstalling cryptography at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a49b59eb-ea69-4fcf-add3-41f8f16da2df\n",
      "    Can't uninstall 'cryptography'. No files were found to uninstall.\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a49b59eb-ea69-4fcf-add3-41f8f16da2df\n",
      "    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n",
      "Successfully installed asn1crypto-1.5.1 cryptography-41.0.5 pyOpenSSL-23.3.0 pyjwt-2.8.0 snowflake-connector-python-3.4.1 sortedcontainers-2.4.0 tomlkit-0.12.2 typing-extensions-4.8.0\n",
      "Python interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install snowflake-connector-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5aacf18-cf8c-4516-86ba-0ea1abbe8f84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: 'Success'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "import uuid\n",
    "\n",
    "# Generate a UUID\n",
    "unique_id = uuid.uuid4()\n",
    "\n",
    "unique_id_str = str(unique_id)\n",
    "\n",
    "# get the current date and time\n",
    "now = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "\n",
    "slack_channel = '#data-pipeline'\n",
    "slack_token = 'xoxb-6188139053732-6182803218965-XHZIaMk1s0li5IgQxd4hFtYg'\n",
    "\n",
    "def post_message_to_slack(text, blocks = None):\n",
    "    \n",
    "    requests.post('https://slack.com/api/chat.postMessage', { 'token': slack_token, 'channel': slack_channel,'text': text })\n",
    "    \n",
    "    return'Success' \n",
    "\n",
    "post_message_to_slack(text=f'[Reference ID -{unique_id_str}] ETL Switzerland Housing data started at  {now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f22115-def4-44cf-a973-b8abe88d856a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-a49b59eb-ea69-4fcf-add3-41f8f16da2df/lib/python3.9/site-packages/snowflake/connector/options.py:103: UserWarning: You have an incompatible version of 'pyarrow' installed (7.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    import snowflake.connector as sf\n",
    "    conn = sf.connect(\n",
    "        user='cdaniel7',\n",
    "        password='redacted',\n",
    "        account='efgtsyw-vh15210',\n",
    "        warehouse='COMPUTE_WH',\n",
    "        database='PROPERTI',\n",
    "        schema='PROPERTI_SCHEMA'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Extracting CSVs from https://public.madd.bfs.admin.ch/ch.zip','ETL Started',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 4 - {e} at {now}')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "869bda0b-66b2-4d68-807f-5a8b8fd17295",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Extracting the zip file from https://public.madd.bfs.admin.ch/ch.zip\n",
    "## 2. Unzipping the following csvs\n",
    "- `eingang_entree_entrata.csv `\n",
    "- `gebaeude_batiment_edificio.csv` \n",
    "- `wohnung_logement_abitazione.csv` \n",
    "- `kodes_codes_codici.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b6817bc-59d6-40ef-ac36-c05f91456cd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  4  678M    4 27.7M    0     0  21.6M      0  0:00:31  0:00:01  0:00:30 21.6M\n",
      " 12  678M   12 83.8M    0     0  36.4M      0  0:00:18  0:00:02  0:00:16 36.4M\n",
      " 18  678M   18  128M    0     0  38.6M      0  0:00:17  0:00:03  0:00:14 38.6M\n",
      " 24  678M   24  165M    0     0  38.6M      0  0:00:17  0:00:04  0:00:13 38.6M\n",
      " 30  678M   30  206M    0     0  39.0M      0  0:00:17  0:00:05  0:00:12 41.6M\n",
      " 38  678M   38  262M    0     0  41.6M      0  0:00:16  0:00:06  0:00:10 46.7M\n",
      " 45  678M   45  312M    0     0  42.6M      0  0:00:15  0:00:07  0:00:08 45.4M\n",
      " 53  678M   53  360M    0     0  43.3M      0  0:00:15  0:00:08  0:00:07 46.4M\n",
      " 60  678M   60  408M    0     0  43.7M      0  0:00:15  0:00:09  0:00:06 48.1M\n",
      " 66  678M   66  453M    0     0  44.0M      0  0:00:15  0:00:10  0:00:05 49.4M\n",
      " 72  678M   72  490M    0     0  43.4M      0  0:00:15  0:00:11  0:00:04 45.7M\n",
      " 76  678M   76  522M    0     0  42.4M      0  0:00:15  0:00:12  0:00:03 42.2M\n",
      " 84  678M   84  571M    0     0  42.8M      0  0:00:15  0:00:13  0:00:02 42.1M\n",
      " 91  678M   91  622M    0     0  43.5M      0  0:00:15  0:00:14  0:00:01 43.2M\n",
      " 97  678M   97  660M    0     0  43.1M      0  0:00:15  0:00:15 --:--:-- 41.3M\n",
      "100  678M  100  678M    0     0  43.4M      0  0:00:15  0:00:15 --:--:-- 43.5M\n",
      "Archive:  ch.zip\n",
      "  inflating: eingang_entree_entrata.csv  \n",
      "  inflating: gebaeude_batiment_edificio.csv  \n",
      "  inflating: kodes_codes_codici.csv  \n",
      "  inflating: wohnung_logement_abitazione.csv  \n",
      "eingang_entree_entrata.csv\n",
      "gebaeude_batiment_edificio.csv\n",
      "kodes_codes_codici.csv\n",
      "wohnung_logement_abitazione.csv\n"
     ]
    }
   ],
   "source": [
    "%sh \n",
    "curl -J -O -o \"ch.zip\" \"https://public.madd.bfs.admin.ch/ch.zip\"\n",
    "unzip ch.zip eingang_entree_entrata.csv gebaeude_batiment_edificio.csv wohnung_logement_abitazione.csv kodes_codes_codici.csv\n",
    "ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd8fdcd0-f189-4832-a591-923cd0403b2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: <snowflake.connector.cursor.SnowflakeCursor at 0x7f251c180fd0>"
     ]
    }
   ],
   "source": [
    "data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'CSVs extracted to Azure Databricks','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "conn.cursor().execute(data_pipeline_audit_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf2998cf-3b19-41ff-a3f1-a4e483b76509",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Appending today's date to the extracted files [This will help with accountability later]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e07d192-e50a-44ff-b1ba-3c8f99962bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: eingang_entree_entrata.csv to eingang_entree_entrata_2023_11_13.csv\n",
      "Renamed: gebaeude_batiment_edificio.csv to gebaeude_batiment_edificio_2023_11_13.csv\n",
      "Renamed: kodes_codes_codici.csv to kodes_codes_codici_2023_11_13.csv\n",
      "Renamed: wohnung_logement_abitazione.csv to wohnung_logement_abitazione_2023_11_13.csv\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "\n",
    "# Get today's date\n",
    "current_date=$(date \"+_%Y_%m_%d\")\n",
    "\n",
    "# Iterate through CSV files in the current directory\n",
    "for file in *.csv; do\n",
    "  new_name=\"${file%.csv}${current_date}.csv\"\n",
    "  mv \"$file\" \"$new_name\"\n",
    "  echo \"Renamed: $file to $new_name\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d29761d-4054-4fc5-9179-9642ecf30e87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: <snowflake.connector.cursor.SnowflakeCursor at 0x7f24e614fac0>"
     ]
    }
   ],
   "source": [
    "data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'CSVs are transformed','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "conn.cursor().execute(data_pipeline_audit_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9809c30-a20d-453d-8849-02d9d3947021",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Declaring AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22cac244-3260-4c04-8a44-940e1282f823",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Settin  AWS access key, secret key, and the S3 bucket and object details\n",
    "import boto3\n",
    "aws_access_key=\"redacted\"\n",
    "aws_secret_key=\"redacted\"\n",
    "s3_bucket=\"chris-properti-ftp\"\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91138209-eea0-41f2-bf04-6c856cbbec11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Cleaning existing files on AWS  latest branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "203cd9e4-d95e-43d2-8568-10fb2d506c1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest/eingang_entree_entrata_2023_11_13.csv\n",
      "latest/gebaeude_batiment_edificio_2023_11_13.csv\n",
      "latest/kodes_codes_codici_2023_11_13.csv\n",
      "latest/wohnung_logement_abitazione_2023_11_13.csv\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3',aws_access_key_id=aws_access_key,aws_secret_access_key=aws_secret_key)\n",
    "bucket = s3.Bucket('chris-properti-ftp')\n",
    "\n",
    "try:\n",
    "    for obj in bucket.objects.filter(Prefix ='latest'):\n",
    "        print(obj.key)\n",
    "        obj.delete()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 13 - {e} at {now}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b3e3c1-a18d-48ce-81e4-54910e1f3151",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Cleaning existing tables on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b969fb9-c7a1-4c82-a1a2-aeba4f0e603d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Cleaning AWS S3 latest folder','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "    conn.cursor().execute(\"truncate table raw_codes_table\")\n",
    "    conn.cursor().execute(\"truncate table refined_codes_table\")\n",
    "\n",
    "    conn.cursor().execute(\"truncate table RAW_GEBAEUDE_BATIMENT_EDIFICIO_TABLE\")\n",
    "    conn.cursor().execute(\"truncate table refined_GEBAEUDE_BATIMENT_EDIFICIO_TABLE\")\n",
    "\n",
    "    conn.cursor().execute(\"truncate table RAW_EINGANG_ENTREE_ENTRATA_TABLE\")\n",
    "    conn.cursor().execute(\"truncate table refined_EINGANG_ENTREE_ENTRATA_TABLE\")\n",
    "\n",
    "    conn.cursor().execute(\"truncate table RAW_WOHNUNG_LOGEMENT_ABITAZIONE\")\n",
    "    conn.cursor().execute(\"truncate table refined_WOHNUNG_LOGEMENT_ABITAZIONE\")\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Truncating existing tables in Snowflake','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 16 - {e} at {now}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "447ee44c-68ea-4063-b4a4-fd3f07f3ac6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Loading wohnung_logement_abitazione.csv to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ede7e95-fe33-48f6-86e2-e7ab168038a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import boto3\n",
    "aws_access_key=\"redacted\"\n",
    "aws_secret_key=\"redacted\"\n",
    "s3_bucket=\"chris-properti-ftp\"\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)\n",
    "\n",
    "try:\n",
    "    filenames = glob.glob(\"wohnung_logement_abitazione*v\")\n",
    "\n",
    "    s3_client = boto3.client('s3', aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)\n",
    "\n",
    "    source_object_key=f\"{filenames[0]}\"\n",
    "    destination_object_key=f\"latest/{filenames[0]}\"\n",
    "    destination_repository_key =f\"archive/wohnung_logement_abitazione/{filenames[0]}\"\n",
    "\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_object_key)\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_repository_key)\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Loading wohnung_logement_abitazione.csv to S3','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 18 - {e} at {now}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb0f34c7-5e35-4fa1-a80d-d81e1a7fe13a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading eingang_entree_entrata.csv to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb7c0e63-89a5-44af-83dd-84ef46a43580",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    filenames = glob.glob(\"eingang_entree_entrata*v\")\n",
    "\n",
    "    source_object_key=f\"{filenames[0]}\"\n",
    "    destination_object_key=f\"latest/{filenames[0]}\"\n",
    "    destination_repository_key =f\"archive/eingang_entree_entrata/{filenames[0]}\"\n",
    "\n",
    "\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_object_key)\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_repository_key)\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Loading eingang_entree_entrata.csv to S3','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 20 - {e} at {now}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4c17ab-8465-4210-8191-890c8ce21a34",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading gebaeude_batiment_edificio.csv to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8205b28d-1c10-498b-b2eb-9af31a27d711",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    filenames = glob.glob(\"gebaeude_batiment_edificio*v\")\n",
    "\n",
    "    source_object_key=f\"{filenames[0]}\"\n",
    "    destination_object_key=f\"latest/{filenames[0]}\"\n",
    "    destination_repository_key =f\"archive/gebaeude_batiment_edificio/{filenames[0]}\"\n",
    "\n",
    "\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_object_key)\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_repository_key)\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Loading gebaeude_batiment_edificio.csv to S3','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 22 - {e} at {now}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70346fd2-fde7-46fb-b9cb-1bc014170462",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading kodes_codes_codici.csv to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "310de17a-1f28-4082-854f-0da57b09a43e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    filenames = glob.glob(\"kodes_codes_codici*v\")\n",
    "\n",
    "    source_object_key=f\"{filenames[0]}\"\n",
    "    destination_object_key=f\"latest/{filenames[0]}\"\n",
    "    destination_repository_key =f\"archive/kodes_codes_codici/{filenames[0]}\"\n",
    "\n",
    "\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_object_key)\n",
    "    s3_client.upload_file(source_object_key,s3_bucket,destination_repository_key)\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Loading kodes_codes_codic.csv to S3','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 24 - {e} at {now}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47f2cb5c-e7c3-49fc-b6ba-003a880e786c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading data into Raw tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fb77ab8-8d25-46da-acae-58d14a3b5d93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    conn.cursor().execute(\"copy into raw_codes_table from @s3_stage file_format = (format_name = 'swiz_csv_format') pattern ='.*kodes.*';\")\n",
    "    conn.cursor().execute(\"copy into RAW_EINGANG_ENTREE_ENTRATA_TABLE from @s3_stage file_format = (format_name = 'swiz_csv_format') pattern ='.*eingang.*';\")\n",
    "    conn.cursor().execute(\"copy into RAW_GEBAEUDE_BATIMENT_EDIFICIO_TABLE from @s3_stage file_format = (format_name = 'swiz_csv_format') pattern ='.*geba.*';\")\n",
    "    conn.cursor().execute(\"copy into RAW_WOHNUNG_LOGEMENT_ABITAZIONE from @s3_stage file_format = (format_name = 'swiz_csv_format') pattern ='.*wohnung.*';\")\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Loading data into Raw tables','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 26 - {e} at {now}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b3c5e52-2afc-4e27-badb-34cbd33f862f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading data into Refined tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f01fd1c0-dd4b-4aa0-8af2-eb9ddd970d86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    conn.cursor().execute(\"insert into refined_codes_table select cecodid::number,       CMERKM,       CODTXTLD,       CODTXTKD,       CODTXTLF,       CODTXTKF,       CODTXTLI,       CODTXTKI,       split(CEXPDAT,'.')[2]||'-'||split(CEXPDAT,'.')[1]||'-'||split(CEXPDAT,'.')[0] as CEXPDAT              from raw_codes_table;\")\n",
    "\n",
    "    conn.cursor().execute(\"insert into refined_EINGANG_ENTREE_ENTRATA_TABLE select        EGID ::number,    \tEDID ::number,    \tEGAID ::number,    \tDEINR ,    \tESID ::number,    \tSTRNAME ,    \tSTRNAMK ,    \tSTRINDX ,    \tSTRSP ::number,    \tSTROFFIZIEL ::number,    \tDPLZ4 ::number,    \tDPLZZ ::number,    \tDPLZNAME ,    \tDKODE ,    \tDKODN ,    \tDOFFADR ::number,        DEXPDAT       from RAW_EINGANG_ENTREE_ENTRATA_TABLE;\")\n",
    "\n",
    "    conn.cursor().execute(\"insert into refined_GEBAEUDE_BATIMENT_EDIFICIO_TABLE select        EGID ::number,\tGDEKT,\tGGDENR ::number,\tGGDENAME ,\tEGRID ,\tLGBKR ::number, \tLPARZ ,\tLPARZSX ,\tLTYP ,\tGEBNR ,\tGBEZ ,\tGKODE ,\tGKODN, \tGKSCE ::number,\tGSTAT ::number,\tGKAT ::number,\tGKLAS ::number,\tGBAUJ ::number,\tGBAUM ::number,\tGBAUP ::number,\tGABBJ ::number,\tGAREA ::number,\tGVOL,\tGVOLNORM ,\tGVOLSCE ,\tGASTW ::number,\tGANZWHG ::number,\tGAZZI ,\tGSCHUTZR ,\tGEBF ,\tGWAERZH1 ::number,\tGENH1 ::number,\tGWAERSCEH1 ::number,     GWAERDATH1,\tGWAERZH2 ::number,\tGENH2 ::number,\tGWAERSCEH2 ::number,    GWAERDATH2,\tGWAERZW1 ::number,\tGENW1 ::number,\tGWAERSCEW1 ::number,    GWAERDATW1,\tGWAERZW2 ,\tGENW2 ,\tGWAERSCEW2,    GWAERDATW2,    GEXPDAT     from RAW_GEBAEUDE_BATIMENT_EDIFICIO_TABLE;\")\n",
    "\n",
    "    conn.cursor().execute(\"insert into refined_wohnung_logement_abitazione select   * from RAW_WOHNUNG_LOGEMENT_ABITAZIONE;\")\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Loading data into Refined tables','ETL Running',CURRENT_TIMESTAMP())\"\n",
    "\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 28 - {e} at {now}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dbf6a72-9c1c-4411-a8ac-dc05d397950c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Cleaning Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df92c7b1-bdce-47be-94fd-3aa74efdbd76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sh \n",
    "rm ch.zip\n",
    "rm *.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c5cdca9-6fa6-407c-b5f8-956eb050159f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[17]: 'Success'"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "\n",
    "    data_pipeline_audit_table = f\"insert into data_pipeline_audit_table values('{unique_id_str}',CURRENT_TIMESTAMP(),'Cleaning directories','ETL Successfully Completed',CURRENT_TIMESTAMP())\"\n",
    "\n",
    "    conn.cursor().execute(data_pipeline_audit_table)\n",
    "\n",
    "\n",
    "    conn.cursor().close()\n",
    "\n",
    "except Exception as e:\n",
    "    now = datetime.datetime.now().replace(microsecond=0)\n",
    "    post_message_to_slack(text=f'[reference id -{unique_id_str}] Exception occured on command 31 - {e} at {now}')\n",
    "\n",
    "now = datetime.datetime.now().replace(microsecond=0)\n",
    "post_message_to_slack(text=f'[reference id -{unique_id_str}] ETL Switzerland Housing data  successfully completed at  {now}')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1581332032808587,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL Switzerland Housing Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
